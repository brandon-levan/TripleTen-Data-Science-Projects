{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 8 Project - Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement -** Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones. My responsability will be to predict whether a customer will leave the bank soon. I have the data on clients’ past behavior and termination of contracts with the bank to do this task.\n",
    "\n",
    "**Project Objective -** I will build a model with the maximum possible F1 score, with the requirement that the F1 score for my model must be at least 0.59.\n",
    "\n",
    "**In this project, I will** - \n",
    "- Download and prepare the data and explain the procedure\n",
    "- Examine the balance of classes\n",
    "  - Train the model without taking into account the imbalance\n",
    "- Improve the quality of the model using at least two approaches to fixing class imbalance\n",
    "  - Use the training set to pick the best parameters\n",
    "  - Train different models on training and validation sets to find the best model\n",
    "- Perform the final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required for the project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# From sklearn get classification models, model evaluation packages, and training data split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split dataset for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For upsampling shuffle\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Accuracy score for decision tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Show all columns when displaying dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below is used to align the tables in the markdown to the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv and save as Churn dataframe\n",
    "churn = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Fields in Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Below is a description for all of the fields in the dataset that I will be working with to build and train my models*\n",
    "\n",
    "**Features**\n",
    "\n",
    " - `RowNumber` — data string index\n",
    " - `CustomerId` — unique customer identifier\n",
    " - `Surname` — surname\n",
    " - `CreditScore` — credit score\n",
    " - `Geography` — country of residence\n",
    " - `Gender` — gender\n",
    " - `Age` — age\n",
    " - `Tenure` — period of maturation for a customer’s fixed deposit (years)\n",
    " - `Balance` — account balance\n",
    " - `NumOfProducts` — number of banking products used by the customer\n",
    " - `HasCrCard` — customer has a credit card\n",
    " - `IsActiveMember` — customer’s activeness\n",
    " - `EstimatedSalary` — estimated salary\n",
    "\n",
    "**Target**\n",
    "- `Exited` — сustomer has left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for Missing Values\n",
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n",
      "\n",
      " Describe Dataframe\n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n",
      "\n",
      " Check Data Types\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      " Check for Duplicate Rows\n",
      "Empty DataFrame\n",
      "Columns: [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
      "Index: []\n",
      "\n",
      " Print First 10 Rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use print so I don't lose outputs\n",
    "\n",
    "# Check for missing values\n",
    "print('Check for Missing Values')\n",
    "print(churn.isna().sum())\n",
    "\n",
    "# Check values for each column\n",
    "print('\\n Describe Dataframe')\n",
    "print(churn.describe())\n",
    "\n",
    "# Check data types\n",
    "print('\\n Check Data Types')\n",
    "print(churn.info())\n",
    "#print(churn.dtypes)\n",
    "\n",
    "#Check for duplicate rows\n",
    "print('\\n Check for Duplicate Rows')\n",
    "print(churn[churn['CustomerId'].duplicated(keep=False)])\n",
    "\n",
    "# Check data\n",
    "print('\\n Print First 10 Rows')\n",
    "churn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few findings which I've listed below from my data exploration. I will address and changes that need to be made from my data exploration in Section 4: Prepare Data From Training\n",
    "1. There are 909 missing values in the Tenure field\n",
    "  - Missing values in this field will be replaced with 0. Another option could be to replace the missing value with the average tenure of all customers.\n",
    "  - After replacing values, datatype shoud be changed to an integer\n",
    "2. There are some fields that may add noise to the model which need to be removed since they don't add value in predicting if a user will churn. \n",
    "  - The fields that will be dropped are RowNumber, CustomerId, Surname\n",
    "  - I could potentially calculate the correlation between these fields and Exited\n",
    "3. There are no duplicated rows or duplicated CustomerIds in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data For Training\n",
    "\n",
    "In this Section 4, I will - \n",
    "- Prepare the data for training\n",
    "  - Replace missing values\n",
    "  - Drop fields\n",
    "- Process all of the feature types\n",
    "  - Convert Categorical Fields into Numerical Using OHE\n",
    "- Create Training, Validation & Test Dataset Before Optimizing For Class Imbalance\n",
    "- Perform Feature Scaling\n",
    "\n",
    "All of these steps must be done before beginning to train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Missing Values in Tenure\n",
    "In the data exploration section above, we found that there were 909 missing values in the Tenure column. I will replace these missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace missing values in Tenure\n",
    "churn['Tenure'].fillna(0, inplace = True)\n",
    "\n",
    "# Check to see if missing values were replaced\n",
    "print(churn['Tenure'].isna().sum())\n",
    "\n",
    "# Convert from float to int\n",
    "churn['Tenure'] = churn['Tenure'].astype('int64')\n",
    "\n",
    "# Check datatype\n",
    "churn['Tenure'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Unneccesary Fields From Dataframe Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.016571371463984713\n",
      "-0.006247986637818783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if there is high correlation between these fields and Exited\n",
    "print(churn['RowNumber'].corr(churn['Exited'])) # Correlation -0.016\n",
    "#churn['Surname'].corr(churn['Exited']) # Name should have no impact on exiting the bank\n",
    "print(churn['CustomerId'].corr(churn['Exited'])) # Correlation -0.006\n",
    "\n",
    "# Remove fields that will reduce model accuracy \n",
    "# Fields to remove are row_number, surname, CustomerId\n",
    "churn = churn.drop(['RowNumber','Surname','CustomerId'], axis=1)\n",
    "\n",
    "# Print resulting df\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Fields into Numerical Using OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Geography and Gender are categorical but do not have an implicit order or ranking, we can use OHE to change the categorical labels to numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Spain' 'Germany']\n",
      "['Female' 'Male']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  \n",
       "0                  0                0              1  \n",
       "1                  0                1              1  \n",
       "2                  0                0              1  \n",
       "3                  0                0              1  \n",
       "4                  0                1              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in the categorical fields Geography and Gender\n",
    "print(churn['Geography'].unique()) # Returns ['France' 'Spain' 'Germany']\n",
    "print(churn['Gender'].unique()) # Returns ['Female' 'Male']\n",
    "\n",
    "# Because there isn't a ranking of these categorical variables, OHE should be used over OrdinalEncoding\n",
    "# This will tell the model that there is an order/rank to these categorical varibales, when there is not\n",
    "churn = pd.get_dummies(churn)\n",
    "\n",
    "# Drop Gender_Male because Gender_Female will contain 1 or 0 if customer is female or male\n",
    "churn = churn.drop(['Gender_Male'], axis=1)\n",
    "\n",
    "# Print sample of dataframe with OHE columns\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training, Validation & Test Dataset Before Optimizing For Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there wasn't a test dataset provided, we will need to make our own from the original dataset. To do this we will split the data in a training, validation, and test dataset with a ratio of rows 3:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 12)\n",
      "(6000,)\n",
      "(2000, 12)\n",
      "(2000,)\n",
      "(2000, 12)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Create target and feature datasets\n",
    "# Exited will be the target\n",
    "target = churn['Exited']\n",
    "features = churn.drop('Exited', axis=1)\n",
    "\n",
    "# Create Training, Validation, and Test Datasets. Split 3:1:1 since I was not provided with a test set\n",
    "# First we will split .40 to get a traning dataset of 60% of the data source \n",
    "# The validiation set will be split in half to get 3 datasets with a ratio of 3:1:1\n",
    "# Set Random State to 12345 to Replicate Training Set in Future\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.40, random_state=12345)\n",
    "\n",
    "# Create a validation and test set from the the original validation set\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid, target_valid, test_size=0.50, random_state=12345)\n",
    "\n",
    "# Check the sizes of the training, validation, and test sets for 3:1:1 ratio\n",
    "# Training \n",
    "print(features_train.shape) # Training set contains 60% of original dataframe rows \n",
    "print(target_train.shape)   # Training set contains 60% of original dataframe rows \n",
    "\n",
    "# Validation\n",
    "print(features_valid.shape) # Validation set contains 20% of original dataframe rows \n",
    "print(target_valid.shape)   # Validation set contains 20% of original dataframe rows \n",
    "\n",
    "# Test\n",
    "print(features_test.shape)  # Test set contains 20% of original dataframe rows \n",
    "print(target_test.shape)    # Test set contains 20% of original dataframe rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "The magnitudes of values and dispersion are higher for the columns like estimated salary and balance compared to Age or Tenure. This means that the algorithm will find these features to be more important than than Age or Tenure. We don't want that. All features should be considered equally important before the algorithm's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "7479    -0.886751 -0.373192  1.104696  1.232271      -0.891560   0.642466   \n",
      "3411     0.608663 -0.183385  1.104696  0.600563      -0.891560  -1.556504   \n",
      "6027     2.052152  0.480939 -0.503694  1.027098       0.830152  -1.556504   \n",
      "1247    -1.457915 -1.417129  0.461340 -1.233163       0.830152   0.642466   \n",
      "3716     0.130961 -1.132419 -0.825373  1.140475      -0.891560  -1.556504   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
      "7479       -1.055187        -0.187705         -1.005013          -0.572475   \n",
      "3411       -1.055187        -0.333945          0.995012          -0.572475   \n",
      "6027        0.947699         1.503095         -1.005013           1.746802   \n",
      "1247       -1.055187        -1.071061          0.995012          -0.572475   \n",
      "3716       -1.055187         1.524268         -1.005013           1.746802   \n",
      "\n",
      "      Geography_Spain  Gender_Female  \n",
      "7479         1.728977      -0.907278  \n",
      "3411        -0.578377       1.102198  \n",
      "6027        -0.578377      -0.907278  \n",
      "1247        -0.578377      -0.907278  \n",
      "3716        -0.578377       1.102198  \n",
      "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "8532    -0.699824 -0.373192 -0.825373 -1.233163       0.830152   0.642466   \n",
      "5799    -0.284431  0.575842 -0.503694 -1.233163      -0.891560   0.642466   \n",
      "5511     0.151731 -0.657902 -1.468729  0.438711      -0.891560   0.642466   \n",
      "7365    -0.876366 -0.278288  1.748053  1.239884      -0.891560   0.642466   \n",
      "7367    -0.481743  0.291132  1.748053 -1.233163       0.830152   0.642466   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
      "8532       -1.055187        -0.015173          0.995012          -0.572475   \n",
      "5799        0.947699         1.471724          0.995012          -0.572475   \n",
      "5511       -1.055187        -1.367107         -1.005013           1.746802   \n",
      "7365        0.947699        -0.786517         -1.005013          -0.572475   \n",
      "7367       -1.055187         1.358533         -1.005013          -0.572475   \n",
      "\n",
      "      Geography_Spain  Gender_Female  \n",
      "8532        -0.578377       1.102198  \n",
      "5799        -0.578377       1.102198  \n",
      "5511        -0.578377      -0.907278  \n",
      "7365         1.728977       1.102198  \n",
      "7367         1.728977      -0.907278  \n",
      "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "7041    -2.226392 -0.088482 -0.825373 -1.233163       0.830152   0.642466   \n",
      "5709    -0.087120  0.006422  1.426375 -1.233163      -0.891560   0.642466   \n",
      "7117    -0.917905 -0.752805  0.139662  0.722307      -0.891560   0.642466   \n",
      "7775    -0.253277  0.101325  1.748053 -1.233163       0.830152   0.642466   \n",
      "8735     0.785204 -0.847708  1.748053  0.615625      -0.891560  -1.556504   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
      "7041       -1.055187         0.647083          0.995012          -0.572475   \n",
      "5709       -1.055187        -1.658410          0.995012          -0.572475   \n",
      "7117        0.947699        -1.369334         -1.005013          -0.572475   \n",
      "7775       -1.055187         0.075086         -1.005013          -0.572475   \n",
      "8735        0.947699        -1.070919          0.995012          -0.572475   \n",
      "\n",
      "      Geography_Spain  Gender_Female  \n",
      "7041        -0.578377      -0.907278  \n",
      "5709        -0.578377       1.102198  \n",
      "7117         1.728977      -0.907278  \n",
      "7775         1.728977      -0.907278  \n",
      "8735        -0.578377      -0.907278  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_556/825491699.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_train[numeric] = scaler.transform(features_train[numeric])\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Create a list of numeric columns in the churn dataset that need to be scaled\n",
    "numeric = ['CreditScore','Age','Tenure','Balance','NumOfProducts'\n",
    "           ,'HasCrCard','IsActiveMember','EstimatedSalary','Geography_France'\n",
    "           ,'Geography_Germany','Geography_Spain','Gender_Female']\n",
    "\n",
    "# Apply feature scaling to the numeric fields in the list\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "# Apply Scaler to Training and Validation Sets\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n",
    "# Check Scaled Numeric Features\n",
    "print(features_train.head())\n",
    "print(features_valid.head())\n",
    "print(features_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model Without Taking into Account Feature/Class Imbalance\n",
    "Now that the data has been cleaned and prepared, and can begin training our model. Because we are predicting whether a customer will churn or not (1 or 0), this is a classification exercise and not a regression exercise as we are not predicting a value; just a label for each customer of the bank. In this section, I will train and tune three models: Decision Tree, Random Forrest, Logistic Regression. \n",
    "\n",
    "\n",
    "**Note** that I will not be accounting for class imbalance of the training data in Section 5, but will address class imbalance in Section 6. After training the models, I will compare the performance of each model before and after accounting for class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit DecisionTreeClassifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At a depth of 1 the accuracy of the model is 0.791\n",
      "At a depth of 2 the accuracy of the model is 0.824\n",
      "At a depth of 3 the accuracy of the model is 0.838\n",
      "At a depth of 4 the accuracy of the model is 0.852\n",
      "At a depth of 5 the accuracy of the model is 0.853\n",
      "\n",
      "The accuracy of the best model is 0.853 at a depth of 5\n"
     ]
    }
   ],
   "source": [
    "# For our Decision Tree Classification Model The Parameter That We Need to Tune is Tree Depth\n",
    "# To determine the most optimal tree depth for the highest model accuracy, we will use the following code\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "# For tree depth between 1 to 6, calculate the optimal tree depth and evaluate model for greatest accuracy\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth) # create a model with the given depth\n",
    "    model.fit(features_train,target_train) # train the model\n",
    "    predictions = model.predict(features_valid) # get the model's predictions\n",
    "    result = accuracy_score(target_valid,predictions) # calculate the accuracy\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "    \n",
    "    # Print model accuracy at each depth\n",
    "    print(\"At a depth of\", depth, \"the accuracy of the model is\", round(result,5))\n",
    "\n",
    "# Print the accuracy of the model and which depth produced the greatest accuracy  \n",
    "print()\n",
    "print(\"The accuracy of the best model is\", round(best_result,5), \"at a depth of\",best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a depth of 5, we will now train our DecisionTreeClassifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Metrics Using Tuned DecisionTreeClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At a depth of 5, the accuracy of the model is 0.853\n",
      "\n",
      "Confusion Matrix\n",
      "[[1533   49]\n",
      " [ 245  173]]\n",
      "\n",
      "The Recall Score is 0.4138755980861244\n",
      "The Precision Score is 0.7792792792792793\n",
      "The F1 Score is 0.5406249999999999\n",
      "The AUC_ROC Score is 0.8227003550711051\n"
     ]
    }
   ],
   "source": [
    "# Use Decision Tree Model for Classification With Depth of 5\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=5)\n",
    "\n",
    "# Fit Model to Traing Dataset\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Use Model to Predict Target Values on Validation Set\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Get Accuracy Score \n",
    "accuracy_valid = accuracy_score(target_valid, predicted_valid)\n",
    "\n",
    "# Print Model Accuracy \n",
    "print(\"At a depth of 5, the accuracy of the model is\", accuracy_valid)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_valid, predicted_valid))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('The AUC_ROC Score is',auc_roc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the logistic regression model on the training set is 0.81883\n",
      "The accuracy of the logistic regression model on the validation set is: 0.8025\n",
      "\n",
      "Confusion Matrix\n",
      "[[1533   49]\n",
      " [ 245  173]]\n",
      "\n",
      "The Recall Score is 0.4138755980861244\n",
      "The Precision Score is 0.7792792792792793\n",
      "The F1 Score is 0.5406249999999999\n",
      "The AUC_ROC Score is 0.7585440874914559\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression Model\n",
    "model = LogisticRegression(random_state=54321, solver=\"liblinear\")\n",
    "\n",
    "# Fit the model to the traning dataset\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Score the model accuracy on the traning and validation data sets\n",
    "score_train = model.score(features_train, target_train)\n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "\n",
    "# Print the accuracy of the model on the traning and validation datasets\n",
    "print(\"The accuracy of the logistic regression model on the training set is\", round(score_train,5))\n",
    "print(\"The accuracy of the logistic regression model on the validation set is:\",round(score_valid,5))\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_valid, predicted_valid))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('The AUC_ROC Score is',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 as the n_estimators, the accuracy of the model is 0.778\n",
      "With 2 as the n_estimators, the accuracy of the model is 0.826\n",
      "With 3 as the n_estimators, the accuracy of the model is 0.8235\n",
      "With 4 as the n_estimators, the accuracy of the model is 0.836\n",
      "With 5 as the n_estimators, the accuracy of the model is 0.838\n",
      "With 6 as the n_estimators, the accuracy of the model is 0.8465\n",
      "With 7 as the n_estimators, the accuracy of the model is 0.847\n",
      "With 8 as the n_estimators, the accuracy of the model is 0.8475\n",
      "With 9 as the n_estimators, the accuracy of the model is 0.8455\n",
      "With 10 as the n_estimators, the accuracy of the model is 0.848\n",
      "\n",
      "The accuracy of the best model on the validation set had n_estimators set to 10 with a score of 0.848\n"
     ]
    }
   ],
   "source": [
    "# For our Random Forest Classification Model The Parameter That We Need to Tune is n_estimators\n",
    "# n_estimators is the number of trees to be used in the forest\n",
    "# To determine the most optimal tree depth for the highest model accuracy, we will use the following code\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "# For n_estimators between 1 and 11, calculate the optimal number of trees to be used in the forest and evaluate model for greatest accuracy\n",
    "for est in range(1, 11):\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "    # Print model accuracy at each depth\n",
    "    print(\"With\", est, \"as the n_estimators, the accuracy of the model is\", round(score,5))\n",
    "\n",
    "# Print the accuracy of the model and which depth produced the greatest accuracy  \n",
    "print()        \n",
    "print(\"The accuracy of the best model on the validation set had n_estimators set to\", best_est, \"with a score of\", round(best_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using n_estimators set to 10, we will now train our RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classification Metrics on Tuned RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With n_estimators set to 5, the accuracy of the model is 0.848\n",
      "\n",
      "Confusion Matrix\n",
      "[[1524   58]\n",
      " [ 246  172]]\n",
      "\n",
      "The Recall Score is 0.41148325358851673\n",
      "The Precision Score is 0.7478260869565218\n",
      "The F1 Score is 0.5308641975308641\n",
      "The AUC_ROC Score is 0.8003322364640484\n"
     ]
    }
   ],
   "source": [
    "# Use RandomForestClassifier for Classification With n_estimators of 10\n",
    "model = RandomForestClassifier(random_state=54321, n_estimators=10)\n",
    "\n",
    "# Fit Model to Traing Dataset\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Use Model to Predict Target Values on Validation Set\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Get Accuracy Score \n",
    "accuracy_valid = accuracy_score(target_valid, predicted_valid)\n",
    "\n",
    "# Print Model Accuracy \n",
    "print(\"With n_estimators set to 5, the accuracy of the model is\", accuracy_valid)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_valid, predicted_valid))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('The AUC_ROC Score is',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note that,** in Section 8, I will compile all of the model performance/evaluation metrics before and after adjusting the training data for class imbalance. I will discuss there each metric and why I decide to move forward with a particualar model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Class Imbalance in the Dataset Using Class Weight Adjustment\n",
    "\n",
    "Class imbalance in the dataset can be handled in several ways - \n",
    "1. **Class Weight Adjustment** - In order to indicate that some observations are more important than others, we can assign a weight to the respective class by using the parameter class_weight='balanced' in our classification models. The algorithm will calculate how many times the class \"0\" occurs more often than the class \"1\". We’ll denote this number as N (an unknown number of times). Because of this, rare class will have a higher weight.\n",
    "2. **Upsampling** - Determine the class with fewer observations. Call it the rare class. Duplicate the rarer class observations several times. Create a new training sample based on the data obtained. The most important tasks are repeated several times to make them easier to remember for the model.\n",
    "3. **Downsampling** - Determine the class with more observations. Let's call it the majority class. We can randomly drop a portion of majority class observations to remove noise for the model to more easily find rare observations.\n",
    "\n",
    "In this section, I will be performning **Class Weight Adjustment** and **Upsampling** to the dataset to try and improve model accuracy. Again, once the models have been trained on the new datasets, I will describe the results of our models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight Adjustment\n",
    "**This will be performed in Section 7** by specifying class_weight='balanced' as a parameter in each classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for upsampling\n",
    "# Function will return an upsampled feature and target traning set to train the model on \n",
    "# Upsample function will create multiple positive class observations by 10 and then shuffle the results to create a new training set\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Return upsampled traning sets\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Run Models to Account for Class Imbalance By Using Upsampled Training Data\n",
    "This section will be very similiar to the model evaluation I performed in **Section 5, HOWEVER,** I will be doing the following in this section\n",
    "1. Run models with parameter `class_weight='balanced'` for class weight adjustment\n",
    "2. Use upsampled training data\n",
    "\n",
    "**After I retrain the models and evaluate their results on the validation data set, I will provide a table with the results of the models before and after factoring for class imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit DecisionTreeClassifier Model Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune DecisionTreeClassifier Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At a depth of 1 the accuracy of the model is 0.7545\n",
      "At a depth of 2 the accuracy of the model is 0.765\n",
      "At a depth of 3 the accuracy of the model is 0.765\n",
      "At a depth of 4 the accuracy of the model is 0.711\n",
      "At a depth of 5 the accuracy of the model is 0.8105\n",
      "\n",
      "The accuracy of the best model is 0.8105 at a depth of 5\n"
     ]
    }
   ],
   "source": [
    "# For our Decision Tree Classification Model The Parameter That We Need to Tune is Tree Depth\n",
    "# To determine the most optimal tree depth for the highest model accuracy, we will use the following code\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "# For tree depth between 1 to 6, calculate the optimal tree depth and evaluate model for greatest accuracy\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced') # create a model with the given depth\n",
    "    model.fit(features_upsampled,target_upsampled) # train the model\n",
    "    predictions = model.predict(features_valid) # get the model's predictions\n",
    "    result = accuracy_score(target_valid,predictions) # calculate the accuracy\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "    \n",
    "    # Print model accuracy at each depth\n",
    "    print(\"At a depth of\", depth, \"the accuracy of the model is\", round(result,5))\n",
    "\n",
    "# Print the accuracy of the model and which depth produced the greatest accuracy  \n",
    "print()\n",
    "print(\"The accuracy of the best model is\", round(best_result,5), \"at a depth of\",best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Metrics Using Tuned DecisionTreeClassifier Model Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At a depth of 5, the accuracy of the model is 0.8105\n",
      "\n",
      "Confusion Matrix\n",
      "[[1341  241]\n",
      " [ 138  280]]\n",
      "\n",
      "The Recall Score is 0.6698564593301436\n",
      "The Precision Score is 0.5374280230326296\n",
      "The F1 Score is 0.5963791267305644\n",
      "The AUC_ROC Score is 0.8310244134068074\n"
     ]
    }
   ],
   "source": [
    "# Use Decision Tree Model for Classification With Depth of 5\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=5, class_weight='balanced')\n",
    "\n",
    "# Fit Model to Traing Dataset\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "\n",
    "# Use Model to Predict Target Values on Validation Set\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Get Accuracy Score \n",
    "accuracy_valid = accuracy_score(target_valid, predicted_valid)\n",
    "\n",
    "# Print Model Accuracy \n",
    "print(\"At a depth of 5, the accuracy of the model is\", accuracy_valid)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_valid, predicted_valid))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('The AUC_ROC Score is',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit LogisticRegression Model Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the logistic regression model on the training set is 0.718\n",
      "The accuracy of the logistic regression model on the validation set is: 0.701\n",
      "\n",
      "Confusion Matrix\n",
      "[[1341  241]\n",
      " [ 138  280]]\n",
      "\n",
      "The Recall Score is 0.6698564593301436\n",
      "The Precision Score is 0.5374280230326296\n",
      "The F1 Score is 0.5963791267305644\n",
      "The AUC_ROC Score is 0.7633756555507836\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression Model\n",
    "model = LogisticRegression(random_state=54321, solver=\"liblinear\", class_weight='balanced')\n",
    "\n",
    "# Fit the model to the traning dataset\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "\n",
    "# Score the model accuracy on the traning and validation data sets\n",
    "score_train = model.score(features_train, target_train)\n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "\n",
    "# Print the accuracy of the model on the traning and validation datasets\n",
    "print(\"The accuracy of the logistic regression model on the training set is\", round(score_train,5))\n",
    "print(\"The accuracy of the logistic regression model on the validation set is:\",round(score_valid,5))\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_valid, predicted_valid))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('The AUC_ROC Score is',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit RandomForestClassifier Model Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune RandomForestClassifier Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 as the n_estimators, the accuracy of the model is 0.747\n",
      "With 2 as the n_estimators, the accuracy of the model is 0.814\n",
      "With 3 as the n_estimators, the accuracy of the model is 0.804\n",
      "With 4 as the n_estimators, the accuracy of the model is 0.826\n",
      "With 5 as the n_estimators, the accuracy of the model is 0.822\n",
      "With 6 as the n_estimators, the accuracy of the model is 0.8295\n",
      "With 7 as the n_estimators, the accuracy of the model is 0.825\n",
      "With 8 as the n_estimators, the accuracy of the model is 0.836\n",
      "With 9 as the n_estimators, the accuracy of the model is 0.8305\n",
      "With 10 as the n_estimators, the accuracy of the model is 0.839\n",
      "\n",
      "The accuracy of the best model on the validation set had n_estimators set to 10 with a score of 0.839\n"
     ]
    }
   ],
   "source": [
    "# For our Random Forest Classification Model The Parameter That We Need to Tune is n_estimators\n",
    "# n_estimators is the number of trees to be used in the forest\n",
    "# To determine the most optimal tree depth for the highest model accuracy, we will use the following code\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "# For n_estimators between 1 and 11, calculate the optimal number of trees to be used in the forest and evaluate model for greatest accuracy\n",
    "for est in range(1, 11):\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est, class_weight='balanced')\n",
    "    model.fit(features_upsampled,target_upsampled)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "    # Print model accuracy at each depth\n",
    "    print(\"With\", est, \"as the n_estimators, the accuracy of the model is\", round(score,5))\n",
    "\n",
    "# Print the accuracy of the model and which depth produced the greatest accuracy  \n",
    "print()        \n",
    "print(\"The accuracy of the best model on the validation set had n_estimators set to\", best_est, \"with a score of\", round(best_score,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Classification Metrics on Tuned RandomForestClassifier Model Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With n_estimators set to 10, the accuracy of the model is 0.839\n",
      "\n",
      "Confusion Matrix\n",
      "[[1461  121]\n",
      " [ 201  217]]\n",
      "\n",
      "The Recall Score is 0.5191387559808612\n",
      "The Precision Score is 0.6420118343195266\n",
      "The F1 Score is 0.5740740740740741\n",
      "The AUC_ROC Score is 0.8138039184848687\n"
     ]
    }
   ],
   "source": [
    "# Use RandomForestClassifier for Classification With n_estimators of 10\n",
    "model = RandomForestClassifier(random_state=54321, n_estimators=10, class_weight='balanced')\n",
    "\n",
    "# Fit Model to Traing Dataset\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "\n",
    "# Use Model to Predict Target Values on Validation Set\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Get Accuracy Score \n",
    "accuracy_valid = accuracy_score(target_valid, predicted_valid)\n",
    "\n",
    "# Print Model Accuracy \n",
    "print(\"With n_estimators set to 10, the accuracy of the model is\", accuracy_valid)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_valid, predicted_valid))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_valid, predicted_valid))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('The AUC_ROC Score is',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Model Performance Before and After Adjusting For Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two tables below describe how each classification model performed for the following metrics - \n",
    "  - **Accuracy -**  Ratio of the total number of correct predictions and the total number of predictions.\n",
    "  - **Recall -** What proportion of actual positives were identified correctly?\n",
    "    - Example - \"for all the patients who actually have heart disease, recall tells us how many we correctly identified as having a heart disease\"\n",
    "  - **Precision -** What proportion of positive identifications were actually correct?\n",
    "    -  Example - \"measure of patients that we correctly identify as having a heart disease out of all the patients actually having it as predicted by the model\"\n",
    "  - **F1 Score -** The F1 score combines precision and recall using their harmonic mean, and maximizing the F1 score implies simultaneously maximizing both precision and recall. \n",
    "  - **AUC_ROC -** ROC AUC score shows how well the classifier distinguishes positive and negative classes. A random model would have an AUC of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Before__ adjusting traning data to account for class imbalance*\n",
    "\n",
    "| Model                         | Accuracy | Recall    | Precision  | F1      | AUC_ROC     |\n",
    "| ----------------              | ------   | ----      | ------     | ----    | ----        |\n",
    "| DecisionTreeClassifier        |  **0.853**   | 0.414     |   0.779    | 0.541   | 0.823   |\n",
    "| LogisticRegression            |  0.802   | 0.414     |   0.779    | 0.541   | 0.758       |\n",
    "| RandomForestClassifier        |  0.848   | 0.411     |   0.747    | 0.530   | 0.800       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__After__ adjusting traning data to account for class imbalance*\n",
    "\n",
    "| Model                         | Accuracy | Recall    | Precision  | F1      | AUC_ROC     |\n",
    "| ----------------              | ------   | ----      | ------     | ----    | ----        |\n",
    "| DecisionTreeClassifier        |  0.810   | **0.669**     |   0.537    | **0.596**   | 0.831       |\n",
    "| LogisticRegression            |  0.701   | 0.669     |   0.537    | 0.596   | 0.763       |\n",
    "| RandomForestClassifier        |  0.839   | 0.519     |   0.642    | 0.574   | 0.813       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the highest metrics after traning the model and fitting to the validation set was the **DecisionTreeClassifier**. However, there were some interested results which I will describe below - \n",
    " - **Without** class imbalance adjustment, the DecisionTreeClassifier model was optimized for higher accuracy (.853 vs .810 after class balancing)\n",
    " - **With** class imbalance adjustment, the DecisionTreeClassifier model had higher Recall, Precision, and consequnely a higher F1 Score. Accuracy of the model dropped from 85.3% to 81.0% but recall increased from 41.4% to 66.9% and AUC_ROC slightly increased. \n",
    " \n",
    "In this situation, I will be moving forward with the DecisionTreeClassifier and I will be training the model on the upsampled data set using the class balancing parameter because this results in better model performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DecisionTreeClassifier on Upsampled Dataset Using Class Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an F1 score greater than 0.59 with an upsampled DTC, we will check now check how the DTC performs on the test dataset (test dataset has had features scaled with StandardScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit DecisionTreeClassifier on Test Data and Evaluate Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train our model with best hyperparameters on upsampled data on train set without tuning hyperparameters to avoid overfitting. I will then check the model on test dataset (test set is scaled with fitted StandardScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At a depth of 5, the accuracy of the model is 0.798\n",
      "\n",
      "Confusion Matrix\n",
      "[[1316  261]\n",
      " [ 143  280]]\n",
      "\n",
      "The Recall Score is 0.6619385342789598\n",
      "The Precision Score is 0.5175600739371534\n",
      "The F1 Score is 0.5809128630705395\n",
      "The AUC_ROC Score is 0.8355347481752318\n"
     ]
    }
   ],
   "source": [
    "# Use Decision Tree Model for Classification With Depth of 5\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=5, class_weight='balanced')\n",
    "\n",
    "# Fit Model to Upsampled Traing Dataset\n",
    "model.fit(features_upsampled,target_upsampled)\n",
    "\n",
    "# Use Model to Predict Target Values on Scaled Test Set\n",
    "predicted_test = model.predict(features_test)\n",
    "\n",
    "# Get Accuracy Score \n",
    "accuracy_valid = accuracy_score(target_test, predicted_test)\n",
    "\n",
    "# Print Model Accuracy \n",
    "print(\"At a depth of 5, the accuracy of the model is\", accuracy_valid)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(target_test, predicted_test))\n",
    "\n",
    "# Print Recall Score\n",
    "print('\\nThe Recall Score is',recall_score(target_test, predicted_test))\n",
    "\n",
    "# Print Precision Score \n",
    "print('The Precision Score is',precision_score(target_test, predicted_test))\n",
    "\n",
    "# Print F1 Score \n",
    "print('The F1 Score is', f1_score(target_test, predicted_test))\n",
    "\n",
    "# Calculate and Print AUC_ROC Score\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('The AUC_ROC Score is',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restate Project Overview -** Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones. My responsability will be to predict whether a customer will leave the bank soon. I have the data on clients’ past behavior and termination of contracts with the bank to do this task.\n",
    "\n",
    "**Project Objective -** I will build a model with the maximum possible F1 score, with the requirement that the F1 score for my model must be at least 0.59.\n",
    "\n",
    "**Findings & Conclusion** - After training the DecisionTreeClassifier on the upsampled training set and fitting the model to the scaled test data, the model produces the following results - \n",
    "\n",
    "*__After__ adjusting traning data to account for class imbalance **before** fitting model on test data*\n",
    "\n",
    "| Model                         | Accuracy | Recall    | Precision  | F1      | AUC_ROC     |\n",
    "| ----------------              | ------   | ----      | ------     | ----    | ----        |\n",
    "| DecisionTreeClassifier        |  0.810   | 0.669     |   0.537    | 0.596   | 0.831       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__After__ traning model on upsampled traning data and fitting model to the test data*\n",
    "\n",
    "\n",
    "| Model                         | Accuracy | Recall    | Precision  | F1      | AUC_ROC     |\n",
    "| ----------------              | ------   | ----      | ------     | ----    | ----        |\n",
    "| DecisionTreeClassifier        |  0.798   | 0.661     |   0.517    | 0.581   | 0.835       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the model to the test set we see a small increase in accuracy and precision, but a very small decrease in model recall, F1 Score and AUC_ROC score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1530,
    "start_time": "2024-06-03T01:22:13.540Z"
   },
   {
    "duration": 10,
    "start_time": "2024-06-03T01:22:15.073Z"
   },
   {
    "duration": 40,
    "start_time": "2024-06-03T01:22:15.085Z"
   },
   {
    "duration": 145,
    "start_time": "2024-06-03T01:22:15.132Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-03T01:22:15.280Z"
   },
   {
    "duration": 47,
    "start_time": "2024-06-03T01:22:15.294Z"
   },
   {
    "duration": 30,
    "start_time": "2024-06-03T01:22:15.343Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-03T01:22:15.376Z"
   },
   {
    "duration": 103,
    "start_time": "2024-06-03T01:22:15.397Z"
   },
   {
    "duration": 105,
    "start_time": "2024-06-03T01:22:15.505Z"
   },
   {
    "duration": 58,
    "start_time": "2024-06-03T01:22:15.613Z"
   },
   {
    "duration": 78,
    "start_time": "2024-06-03T01:22:15.674Z"
   },
   {
    "duration": 723,
    "start_time": "2024-06-03T01:22:15.756Z"
   },
   {
    "duration": 134,
    "start_time": "2024-06-03T01:22:16.481Z"
   },
   {
    "duration": 24,
    "start_time": "2024-06-03T01:22:16.618Z"
   },
   {
    "duration": 176,
    "start_time": "2024-06-03T01:22:16.645Z"
   },
   {
    "duration": 73,
    "start_time": "2024-06-03T01:22:16.823Z"
   },
   {
    "duration": 133,
    "start_time": "2024-06-03T01:22:16.900Z"
   },
   {
    "duration": 1231,
    "start_time": "2024-06-03T01:22:17.036Z"
   },
   {
    "duration": 230,
    "start_time": "2024-06-03T01:22:18.270Z"
   },
   {
    "duration": 81,
    "start_time": "2024-06-03T01:22:18.503Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "496px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
